I said I was going to talk about test-driven development.  I got overly ambitious about doing so and now have a mess on my hands.  I had drafted the following to send to sigcf.:
Hey, I said I was going to talk about TDD.  I guess I should do that.
I'll draft something to send to the firehose and then try to refine it before I send out my next slow newsletter to the rest of you.  I'll start with what TDD is and why I would rather use proofs than tests if possible, and then I'll talk about my recent thoughts about how to cheat at every step of TDD until it doesn't even look recognizable.

I started trying to make good on that, even though I hadn't sent it yet, and I got -- you guessed it -- bogged down.  I also kept putting it off, and when I finally got started on it, the ideas flowed like a siphon until I couldn't type as fast as they arrived.  Then I had other things I was scheduled to do, so I had to stop until those appointments were over, and of course I didn't care to pick up where I left off when I got back from a change of scenery.
So I'm going to send you guys the first chunk of what I wrote about that and ask for help deriving something worth sending them from it.
Without further ado:

Test-driven development (TDD) is when you write software by writing tests and making them pass, in that order.  You start by writing a failing test, and then you write as little code as possible to make that one test pass without breaking any other tests you may have already written, and then you go and clean up the ugly code you wrote.  This cycle is called "red, green, refactor" or "red, green, clean".  The "refactor" in that first name for the cycle is a technical term that basically means changing how things are structured without changing what they accomplish.  In TDD, "same" can be thought of as "passes the same tests", so refactoring could be any change that doesn't cause any tests to fail that weren't already failing, but programmers will probably argue with you if you make a major change to some untested behavior and call it a refactoring.  Besides, you should avoid having untested behavior in your program anyway if you're doing TDD, because it's tempting to rely on everything you have, and anything not protected by a test is fair game for your coworker to break.
What's a test?  TDD benefits from automated testing, but software testing also includes manual testing.  A manual testing step is like a checklist item, where there's a well-defined procedure for running the software under test into a specific known state, giving it specific inputs once it is in that state, and then observing the resulting outputs and comparing them to the expected ones.  This can be very tedious, so we try to express these testing steps in terms of things we can write programs to do.  Those programs are automated tests: programs that check the behavior of other programs.  Test-driven development is when you let testing drive the process by which you create software.  You decide what features you want, you write the automated testing programs first, and then you make your program-under-test exhibit the behaviors that the automated test suite tests for.
I've heard people say that unit tests are good and integration tests aren't.  I'm not so sure I care about the distinction.  Integration tests are end-to-end and attempt to exercise the whole program, including the interactions between parts of the program.  Unit tests test the smallest pieces of your program and, under TDD, define what counts as correct behavior for those pieces.
Personally, I think mathematical proof is superior to finite test suites.  Automated theorem proving is hard, though, so I wouldn't want to have to write all my programs that way.  I have only a few semesters' worth of experience at it, and I wasn't very good at it.  Still, I'd like to practice and get better at writing theorems that computers can prove about my programs and at writing programs that are easy to write theorems about.
Hardware is more expensive than software.  A small mistake can cost millions of dollars.  Software has a lot more leeway, as you can often just push out a patch to fix bad software, and so most people with money don't want to spend that money making software be as reliable as hardware is.  Because of this, there is a pretty big difference between what professionalism looks like in software versus hardware, in terms of how reliable the product has to be before it is considered "good enough" to sell to people.  I'm not a fan of software that costs money anyway, so I'm definitely not about to pay extra for someone to make software that actually works, as I'm not even trying to help move the market in the direction I'd like to see it go.
